= 2. CI/CDパイプラインの構築 – 30分
:imagesdir: ../assets/images

== 本演習の目標

本演習の目標は、 link:https://access.redhat.com/documentation/en-us/openshift_container_platform/4.11/html-single/cicd/index#op-detailed-concepts[OpenShift Pipelines^]　を使用して、モダナイゼーションされた「Customers」アプリケーションを OpenShift に構築してデプロイすることです。本演習では、以下の手順を実施します。

* https://tekton.dev/[Tekton^] Pipelineを使用して、Apache Tomcatの代わりに、ランタイムとしてRed Hat JBoss Web Serverを使用し、新しくモダナイゼーションされたアプリケーションの構築およびデプロイの実施
* OpenShift Container Platform上で稼働中のOracleデータベースVMに、 *customers* サービスが接続するための設定の実施
* *customers* サービスのテスト

== 2.1. HelmによるOracle DBMS接続の更新

=== 2.1.1. OpenShiftでHelmを使用する理由

https://docs.openshift.com/container-platform/4.10/applications/working_with_helm_charts/understanding-helm.html[Helm^] は、ハイブリッドクラウドのあらゆる場所で、Kubernetesを用いてコンテナ化されたアプリケーションのパッケージングおよびデプロイを標準化、簡素化するパッケージ＆インストールマネージャです。これにより、開発者が作成したアプリケーションをパッケージ化し、組織内外の誰もが簡単に共有およびデプロイできるようにします。

またHelmを用いることで、アプリケーションのインストールや基本的な構成管理といった *Day-1* タスクや、シンプルなアップグレードやロールバックの実行というような *Day-2* オペレーションを自動化するためにも使用可能です。

=== 2.1.2. 新しいJDBC構成向けにHelmチャートの更新

現在、OpenShiftクラスタにある *customers* アプリケーションは、依然としてRHV上で動作するOracleデータベースに接続しようとするため、接続に失敗している状況となります。この問題を解決するには、OpenShift virtualization上でマイグレーションしたOracleデータベースを指定している *JDBC* の設定を更新する必要があります。

[IMPORTANT]
====
今回のハンズオンラボにおいては、演習時間を確保するため、SREチームにより、すでに *retail-%USERID%* プロジェクトでOracleデータベースが稼働しているVMはOpenShift virtualizationにマイグレーション済みです。
====

JDBCの設定は現在、モダナイゼーションされたGlobex RetailのシステムのDay-1およびDay-2オペレーションを自動化するためにHelmチャートで管理されています。link:https://codeserver-codeserver-%USERID%.%SUBDOMAIN%[VS Code server^] に戻り、 *helm/customer-tomcat-gitops* ディレクトリを確認してください。

`persistence.properties` ファイルの内容を見て、HelmチャートでJDBC接続の設定をどのように定義可能か確認します。

image::gitops-persistence.png[gitops-persistence]

[NOTE]
====
*JDBCの設定* を更新する際の、開発者目線でのベストプラクティスな方法として、VS Code Serverのローカル環境にて設定変更を行うことが挙げられます。そして作業後、その変更をコミットしてGiteaリポジトリにプッシュすることで、 `OpenShift pipeline と GitOps` をトリガーにして、OpenShiftの `ConfigMap` と `Secret` オブジェクトを自動的にアップデートされます。
====

link:https://argocd-server-retail-%USERID%.%SUBDOMAIN%[ArgoCD のwebコンソール^]　にアクセスし、 `LOG IN VIA OPENSHIFT` をクリックしてください。

image::argocd-login.png[argocd-login]

その後、OpenShiftのログイン認証情報を入力してください。

* Username: `%USERID%`
* Password: `{openshift-password}`

ログイン後、アプリケーションはまだ古いデータベースのホスト名（例： *oracle-db-database* ）を参照しているため、 `customers-tomcat-gitops`　のステータスが *Degraded* であることが確認できます。

`applications` をクリックしてください。
 
image::argocd-application.png[argocd-application]

`APP DETAILS` をクリックすると、アプリケーションの詳細ページが表示されます。次に、 `PARAMETER` タブに切り替えて、 `EDIT` をクリックしてください。

image::argocd-application-details.png[argocd-application-details]

`customerDatabase` のキーおよび値を、Red Hat OpenShift上のOracleの仮想マシンを参照する以下のデータへ置き換えてください。それぞれ以下のような値になります。

* customerDatabase.hostname: `oracle-database`
* customerDatabase.password: `redhat`

image::argocd-application-update.png[argocd-application-update]

置き換え後、 `SAVE` をクリックし、右上の `X` をクリックしてポップアップウィンドウを閉じます。

アプリケーションオブジェクトを更新したため、 `customers-tomcat-gitops` アプリケーションのステータスが `OutOfSync` と表示されるようになり、デプロイされたものとは異なる状態になっています（そのため、「OutOfSync」となっています）。

image::argocd-application-outofsync.png[argocd-application-outofsync]

`SYNC` をクリックし、その後、左のポップアップウィンドウで `SYNCHRONIZE` をクリックしてください。

image::argocd-application-sync.png[argocd-application-sync]

アプリケーションの同期にはしばらく時間がかかるため、完了までお待ちください。

image::argocd-application-synced.png[argocd-application-synced]

このリンクをクリックし、OpenShift Web Consoleに戻り、 link:https://console-openshift-console.%SUBDOMAIN%/k8s/ns/retail-%USERID%/secrets/customers-secret[customers-secret^] を確認してください。確認すると、JDBCの設定値が更新されていることが分かります。

image::argocd-application-secret.png[argocd-application-secret]

== 2.2. OpenShift Pipelinesの実行

=== 2.2.1 OpenShift Pipelinesを使用する理由

OpenShift Pipelinesは、パイプラインを設計、実行するために https://tekton.dev[Tekton^] をベースとした *KubernetesネイティブのCI/CD* フレームワークを提供しており、CI/CDパイプラインの各ステップを独自のコンテナで実行し、パイプラインの要求に応じて各ステップを独立して拡張できるように設計されています。

OpenShift Pipelinesは、Kubernetes/OpenShiftをCRD（Custom Resource Definition）で拡張することで、Kubernetesの拡張性、セキュリティ、デプロイの容易性を高める観点から、 `パイプライン`、 `タスク`、 `ステップ` などCI/CDコンセプトをネイティブにするソリューションです。

image::tekton-concept.png[tekton-concept]

パイプラインは、定義された複数の _ステップ_ にまたがって _タスク_ を実行します。実行するタスクには、それぞれ単一の使用用途があります。

*	*Clone Repository* は、ターゲットのGitリポジトリからソースコードをダウンロードします。
* *Build from Source* は、ソースコードからアプリケーションアーティファクトのビルドを実行します。このタスクにより、ターゲットアプリケーションソースが利用可能なリポジトリからターゲットサブディレクトリを選択できるように調整され、単一のリポジトリで複数のアプリケーション、コンポーネントを利用できるようになりました。 *しかしながら通常は、このような方法で異なるサービスやコンポーネントをバージョン管理することは、非常に好ましくありません。* 最適なアプローチとして、各コンポーネントのライフサイクルが独立している必要があるため、専用のリポジトリを持つことが推奨されますが、本演習での学習ため、このようにデモ素材を1つのリポジトリに集約しています。
* *Build Image* は、アプリケーションにパッケージされたDockerfileを使用してイメージを構築し、ターゲットレジストリにプッシュします。このイメージには、含まれるソースのショートコミットハッシュがタグ付けされます。
*	*Update Manifest* は、ショートコミットハッシュタグを使って、Gitのアプリケーションマニフェストを更新し、新しくビルドされたイメージを指します。アプリケーションのデプロイはArgoCDに委ねられ、ArgoCDは設定リポジトリに変更がないか継続的にポーリングし、それに応じてすべてのOpenShiftオブジェクトを作成および更新しています。

パイプラインには、以下のパラメータが設定可能です。

* *git-url*: 対象のGitリポジトリのURL
* *git-branch*: 作業対象のGitブランチ（デフォルト: _main_）
* *app-subdir*: アプリケーションのソースコードが格納されているリポジトリからサブディレクトリを指定
* *target-namespace*: アプリケーショのデプロイ先のNamespaceプロジェクト
* *target-registry*: ビルドしたイメージをプッシュするレジストリ（デフォルト: _image-registry.openshift-image-registry.svc:5000_、OpenShiftコンテナの内部レジストリになります）

=== 2.2.2 「Customers」パイプラインの実行

Webhookやイベントリスナー、トリガーを設定し、ソースコードのコミット時にパイプラインを自動実行することが可能です。

しかし、本演習においては、この設定を簡素なものにするため、パイプラインの実行を手動で実行します。

まず、新しくブラウザを開き、 link:https://console-openshift-console.%SUBDOMAIN%/dev-pipelines/ns/cicd-%USERID%[OpenShift Pipleline^] にアクセスしてください。

OpenShiftクラスタにログインしたことがない場合は、以下の認証情報を使用し、ログインしてください。

image::openshift_login.png[openshift_login]

以下の認証情報を使用して、ログインします。

* Username: `%USERID%`
* Password: `{openshift-password}`

ログイン後、Developerパースペクティブの `cicd-%USERID%` プロジェクトに、あらかじめ定義された `java-deployment pipeline` が表示されます。

`java-deployment pipeline` をクリックしてください。

image::ama-pipeline.png[ama-pipeline]

*Actions* ドロップダウンメニューの `Start` をクリックし、パイプラインを実行してください。

image::ama-pipeline-start.png[ama-pipeline-start]

*PipelineRun* は、パイプラインの単発実行を表し、この特定の呼び出しに使用されるソースコードとイメージリソースを結び付けます。

このダイアログボックスでは、 _build-artifact_ ステップのソースリポジトリおよび _update-manifest-and-push_ ステップで展開するターゲットNamespaceに対して、最終的なターゲット値をバインドできます。以下の値を使用してワークスペースセクションを更新し、その後 *Start* をクリックしてください。

[NOTE]
====
その他のキーの値（ `git-url, git-branch, app-subdir, target-namespace, and target-registry` ）は、変更する必要はありません。
====

* ws: `customers-pvc` in *PersistentVolumeClaim*

image::ama-pipeline-start-popup.png[ama-pipeline-start-popup]

*java-deployment-pipeline* を起動するとすぐに _pipelinerun_ がインスタンス化され、パイプラインで定義されているタスクを実行するためのpodが作成されます。パイプライン起動から数分ほどで、正常完了します。ステップにカーソルを合わせると、ステップの進捗状況に関するスナップショットを簡単に確認でき、ステップをクリックすると、対象のステップに関する詳細なログが確認できます。

image::ama-pipeline-complete.png[ama-pipeline-complete]

=== 2.2.3 Topologyビューをより良くするためにラベルを追加

Globex Retailのシステムでは、OpenShiftクラスタに複数のマイクロサービスを導入しています。各マイクロサービスは、それぞれ他のマイクロサービスおよびデータベースとの間に複雑な関連性を持っています。このアーキテクチャは、開発者やSREチームからすると、瞬時に理解できるものではないかもしれません。そのような状況に対応できるように、OpenShift Developerコンソールでは、構成を理解する際にお役立ていただけるラベルやアノテーションを備えた直感的な `topology` ビューを提供しています。このラベルは、同じNamespaceにデプロイされたアプリケーション間の明示的な関連性を詳述します。

以下のコマンドを実行し、各アプリケーションで使用されている _言語_、_フレームワーク_、_ランタイム_ を表示するために、各デプロイメントにラベルおよびアノテーションを追加してください。

[.console-input]
[source,bash]
----
oc project retail-%USERID% && \
oc label deployment/inventory app.kubernetes.io/part-of=inventory app.openshift.io/runtime=quarkus --overwrite && \
oc label deployment/postgresql-inventory app.kubernetes.io/part-of=inventory app.openshift.io/runtime=postgresql --overwrite && \
oc annotate deployment/inventory app.openshift.io/connects-to='[{"apiVersion":"apps/v1","kind":"Deployment","name":"postgresql-inventory"}]' --overwrite && \
oc label deployment/orders app.kubernetes.io/part-of=orders app.openshift.io/runtime=spring --overwrite && \
oc label deployment/postgresql-orders app.kubernetes.io/part-of=orders app.openshift.io/runtime=postgresql --overwrite && \
oc annotate deployment/orders app.openshift.io/connects-to='[{"apiVersion":"apps/v1","kind":"Deployment","name":"postgresql-orders"}]' --overwrite && \
oc label deployment/customers app.kubernetes.io/part-of=customers app.openshift.io/runtime=tomcat --overwrite && \
oc annotate deployment/customers app.openshift.io/connects-to='[{"apiVersion":"apps/v1","kind":"VirtualMachine","name":"oracle-database"}]' --overwrite && \
oc label deployment/ordersfrontend app.kubernetes.io/part-of=ordersfrontend app.openshift.io/runtime=nodejs --overwrite && \
oc annotate deployment/ordersfrontend app.openshift.io/connects-to=gateway --overwrite && \
oc label deployment/gateway app.kubernetes.io/part-of=gateway app.openshift.io/runtime=spring --overwrite && \
oc annotate deployment/gateway app.openshift.io/connects-to='["inventory","orders","customers",{"apiVersion":"apps/v1","kind":"Deployment","name":"customers"}]' --overwrite
----

[NOTE]
====
`gateway` と `customers` との間にコネクションがない可能性もありますが、その場合、`gateway` から `customers` の「Dev Console」に矢印をドラッグすることでコネクションを追加できます。この情報は、両者のコネクションが存在していること示す視覚的な情報となります。
====

その後、Developerパースペクティブにある `retail-%USERID%` プロジェクトの link:https://console-openshift-console.%SUBDOMAIN%/topology/ns/retail-%USERID%?view=graph[Topology ビュー^] に戻ると、アプリケーションのデプロイメントが以下のように表示されます。

image::app-topology.png[app-topology]

== おめでとうございます!

以上で、CI/CDパイプラインを使用して、モダナイゼーションされたお客様のアプリケーションを、OpenShiftに構築およびデプロイし、お客様のマイクロサービスをOpenShift Virtualizationで実行されている新しいOracleデータベースに接続することができました。

次のステップでは、はじめに `gateway` をアップデートして、Dynamic Discoveryを使用して `New Customers` サービスに接続します（静的IPアドレスとの比較）。

その後、このアプリケーションをOpenShift GitOpsと統合することで、アプリケーションのコンポーネントを宣言的に記述し、デプロイされたアプリケーションを自動的に同期させることができます。このステップは、ソフトウェアの提供方法を改善し、コンフィグレーションドリフトが発生する可能性を最小限に抑え、長期にわたってより良い可監査性を実現するために重要なものとなります。次のステップへ進んでください。
